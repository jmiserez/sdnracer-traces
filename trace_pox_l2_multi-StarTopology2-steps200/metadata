{
  "additional_metadata": null,
  "argv": [
    "./simulator.py",
    "-c",
    "config/trace_pox_l2_multi.py"
  ],
  "cwd": "/home/ahassany/repos/jsts",
  "host": {
    "cpu_info": "Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz",
    "free": "total       used       free     shared    buffers     cached\nMem:       4045244     287564    3757680       5664      23244     164868\n-/+ buffers/cache:      99452    3945792\nSwap:      4192252          0    4192252",
    "name": "stsdev",
    "num_cores": "2",
    "uptime": "22:22:33 up 19:25,  1 user,  load average: 0.06, 0.03, 0.05"
  },
  "modules": {
    "hassel": {
      "branch": "HEAD",
      "commit": "31afb29fa66783f5a66765bc186509b65ffc023e",
      "diff": "",
      "status": "HEAD detached at 31afb29\nnothing to commit, working directory clean"
    },
    "pox": {
      "branch": "hb",
      "commit": "1ce3d8777c2a1bbaea68c4727a6f1ff59fe7a5d9",
      "diff": "diff --git a/pox/forwarding/consistency.py b/pox/forwarding/consistency.py\nindex 24be0cb..8fd3110 100644\n--- a/pox/forwarding/consistency.py\n+++ b/pox/forwarding/consistency.py\n@@ -501,6 +501,9 @@ class Main(EventMixin):\n     #self.handlers[f2].redirect_serivce(host_ips[service1], fs_ports[monitor])\n     # 4- Update I to forward G traffic to F2, while continuing to\n     #    forward U traffic to F1 and S and F traffic to F3.\n+    self.log.info(\"Sleeping for %d secs\", self.consistent_sleep)\n+    time.sleep(5)\n+    self.log.info(\"Woke up after %d secs\", self.consistent_sleep)\n     self.handlers[internal].redirect_traffic(guest, internal_ports[f2])\n \n   def update_version(self):\ndiff --git a/pox/forwarding/l2_fwd.py b/pox/forwarding/l2_fwd.py\nindex 7b5e12f..27fa175 100644\n--- a/pox/forwarding/l2_fwd.py\n+++ b/pox/forwarding/l2_fwd.py\n@@ -261,6 +261,7 @@ class S2(EventMixin):\n       self.inconsistent_PacketIn(event)\n \n   def _handle_BarrierIn(self, event):\n+    raise RuntimeError()\n     self.log.info(\"BARRIER REPLY%s\", event.xid)\n     t = (self.dpid, event.xid)\n     if t in waiting_msgs:\n@@ -282,6 +283,10 @@ class Main(EventMixin):\n     self.consistent = consistent\n     self.use_barrier = use_barrier\n \n+    print \"CORE\", core\n+    print \"DIR core\", dir(core)\n+    print \"EVENT HANDLERS\", core._eventMixin_handlers\n+\n   def _handle_ConnectionUp (self, event):\n     log.debug(\"Connection %s\", event.connection)\n     dpid = dpidToStr(event.dpid)\n@@ -294,6 +299,10 @@ class Main(EventMixin):\n       self.handlers[s1].s2_conn = self.handlers[s2].s2_conn\n       self.handlers[s2].s1_conn = self.handlers[s1].s1_conn\n \n+    print \"CORE\", core\n+    print \"DIR core\", dir(core)\n+    print \"EVENT HANDLERS\", core._eventMixin_handlers\n+\n \n def launch(consistent=False, use_barrier=True):\n   core.registerNew(Main, consistent=str_to_bool(consistent),",
      "status": "On branch hb\nYour branch is up-to-date with 'origin/hb'.\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git checkout -- <file>...\" to discard changes in working directory)\n\n\tmodified:   pox/forwarding/consistency.py\n\tmodified:   pox/forwarding/l2_fwd.py\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\n\tpox/forwarding/l2_multi_new.py\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")"
    },
    "sts": {
      "branch": "hb",
      "commit": "f7cc0b2d87d3fbc3c57e6ba5cbd22c6953e2f8cf",
      "diff": "diff --git a/config/fuzzer_params.py b/config/fuzzer_params.py\nindex 1807a9a..e8b90ff 100644\n--- a/config/fuzzer_params.py\n+++ b/config/fuzzer_params.py\n@@ -11,7 +11,7 @@ link_failure_rate = 0.0\n link_recovery_rate = 1.0\n controller_crash_rate = 0.0\n controller_recovery_rate = 1.0\n-traffic_generation_rate = 0.10\n+traffic_generation_rate = 0.35\n host_migration_rate = 0.0\n intracontroller_block_rate = 0.0\n intracontroller_unblock_rate = 0.0\ndiff --git a/config/trace_floodlight_hb_learningswitch.py b/config/trace_floodlight_hb_learningswitch.py\nindex 16a1850..c069e84 100644\n--- a/config/trace_floodlight_hb_learningswitch.py\n+++ b/config/trace_floodlight_hb_learningswitch.py\n@@ -12,12 +12,12 @@ from config.application_events import AppCircuitPusher\n \n start_cmd = ('''java -ea -Dlogback.configurationFile=./src/main/resources/logback-trace.xml -jar '''\n              '''./target/floodlight.jar '''\n-              '''-cf ./src/main/resources/hb_learningswitch.properties''')\n+              '''-cf ./src/main/resources/learningswitch.properties''')\n \n # Uncomment this if you are running Floodlight separately, e.g. for debugging in Eclipse. There must be a controller listening on port 6633.\n-# start_cmd = '''echo \"no-op\"'''\n+start_cmd = '''echo \"no-op\"'''\n \n-controllers = [ControllerConfig(start_cmd, cwd='../floodlight', address=\"127.0.0.1\", port=6633)]\n+controllers = [ControllerConfig(start_cmd, cwd='../jfloodlight', address=\"192.168.56.1\", port=6633, controller_type='dummy')]\n \n \n \ndiff --git a/config/trace_pox_l2_consistency.py b/config/trace_pox_l2_consistency.py\nindex 4369691..8b7b2cd 100644\n--- a/config/trace_pox_l2_consistency.py\n+++ b/config/trace_pox_l2_consistency.py\n@@ -10,7 +10,7 @@ from sts.happensbefore.hb_logger import HappensBeforeLogger\n \n \n consistent = True\n-barriers= True\n+barriers= False\n \n # Use POX as our controller\n start_cmd = ('''./pox.py --verbose '''\ndiff --git a/config/trace_pox_l2_multi.py b/config/trace_pox_l2_multi.py\nindex a935594..b11a2cb 100644\n--- a/config/trace_pox_l2_multi.py\n+++ b/config/trace_pox_l2_multi.py\n@@ -20,16 +20,16 @@ start_cmd = ('''./pox.py --verbose '''\n controllers = [ControllerConfig(start_cmd, cwd=\"pox/\")]\n \n num = 2\n-#topology_class = StarTopology\n-#topology_params = \"num_hosts=%d\" % num\n+topology_class = StarTopology\n+topology_params = \"num_hosts=%d\" % num\n #topology_class = MeshTopology\n #topology_params = \"num_switches=%d\" % num\n # topology_class = GridTopology\n # topology_params = \"num_rows=3, num_columns=3\"\n-topology_class = BinaryLeafTreeTopology\n-topology_params = \"num_levels=%d\" % num\n+#topology_class = BinaryLeafTreeTopology\n+#topology_params = \"num_levels=%d\" % num\n \n-steps = 100\n+steps = 200\n # Where should the output files be written to\n results_dir = \"traces/trace_pox_l2_multi-%s%d-steps%s\" % (topology_class.__name__, num, steps)\n \ndiff --git a/pox b/pox\nindex 3f11583..1ce3d87 160000\n--- a/pox\n+++ b/pox\n@@ -1 +1 @@\n-Subproject commit 3f1158333a8ada3d3d310fb2cb1150caf011021a\n+Subproject commit 1ce3d8777c2a1bbaea68c4727a6f1ff59fe7a5d9-dirty\ndiff --git a/sts/happensbefore/hb_graph.py b/sts/happensbefore/hb_graph.py\nindex 34f5f0f..121b4c1 100755\n--- a/sts/happensbefore/hb_graph.py\n+++ b/sts/happensbefore/hb_graph.py\n@@ -802,29 +802,21 @@ class HappensBeforeGraph(object):\n     Finds all the races related each packet trace\n     \"\"\"\n     races = []\n-    just_first = False\n     for trace in self.packet_traces:\n       tmp = self.get_racing_events(trace, True)\n       if not tmp:\n         continue\n-      if len(tmp) == 1:\n-        send = trace.graph['host_send']\n-        if trace.has_edge(send.eid, tmp[0].i_event.eid) or\\\n-          trace.has_edge(send.eid, tmp[0].k_event.eid):\n-          just_first = True\n-      races.append((trace, tmp, just_first))\n+      races.append((trace, tmp,))\n     return races\n \n-  def summarize_per_packet_inconsistent(self, traces_races, add_just_first=True):\n+  def summarize_per_packet_inconsistent(self, traces_races):\n     \"\"\"\n     If two packets are inconsistent, but they race with the same set of writes,\n     then only one will be reported\n     \"\"\"\n     result = {}\n     removed = defaultdict(list)\n-    for trace, races, just_first in traces_races:\n-      if just_first and not add_just_first:\n-        continue\n+    for trace, races, versions in traces_races:\n       # First get the writes\n       writes = []\n       for race in races:\n@@ -832,14 +824,14 @@ class HappensBeforeGraph(object):\n           writes.append(race.i_op.eid)\n         if isinstance(race.k_op, TraceSwitchFlowTableWrite):\n           writes.append(race.k_op.eid)\n-      key = (tuple(sorted(writes)), just_first)\n+      key = (tuple(sorted(writes)))\n       if key in result:\n-        removed[key].append((trace, races, just_first))\n+        removed[key].append((trace, races, versions))\n       else:\n-        result[key] = (trace, races, just_first)\n+        result[key] = (trace, races, versions)\n     return result.values()\n \n-  def print_racing_packet_trace(self, trace, races, just_first, label):\n+  def print_racing_packet_trace(self, trace, races, label):\n     \"\"\"\n     first is the trace\n     second is the list of races\n@@ -878,35 +870,119 @@ class HappensBeforeGraph(object):\n     print \"Saving all races graph in\", name\n     nx.write_dot(graph, os.path.join(self.results_dir, name))\n \n-  def find_per_packet_inconsistent(self, ignore_first=False, summarize=True):\n+  def check_covered(self, ordered_trace_events, races):\n+    # Cannot be covered if there is only one race\n+    if len(races) <= 1:\n+      return False\n+\n+    # Collect reads and writes\n+    by_writes = {}\n+    by_reads = {}\n+    for race in races:\n+      if isinstance(race.i_op, TraceSwitchFlowTableWrite):\n+        wr = race.i_event.eid\n+        rd = race.k_event.eid\n+      else:\n+        rd = race.i_event.eid\n+        wr = race.k_event.eid\n+      if wr not in by_writes:\n+        by_writes[wr] = []\n+      if rd not in by_reads:\n+        by_reads[rd] = []\n+      by_writes[wr].append(rd)\n+      by_reads[rd].append(wr)\n+\n+    ordered_racing_reads = []\n+    for eid in ordered_trace_events:\n+      if eid in by_reads:\n+        ordered_racing_reads.append(eid)\n+\n+    # Try to find if the two writes have HB relations between them\n+    found_paths = []\n+    for i in range(1, len(ordered_racing_reads)):\n+      r1 = ordered_racing_reads[i-1]\n+      r2 = ordered_racing_reads[i]\n+\n+      for wr1 in by_reads[r1]:\n+        for wr2 in by_reads[r2]:\n+          if not nx.has_path(self.g, wr2, wr1):\n+            found_paths.append((wr2, wr1))\n+    for wr2, wr1 in found_paths:\n+      write1 = self.g.node[wr1]['event']\n+      write2 = self.g.node[wr2]['event']\n+      delta = write1.operations[0].t - write2.operations[0].t\n+      if self.race_detector.add_hb_time and delta >= self.race_detector.ww_delta:\n+        continue # Covered because of time\n+      # TODO(AH): Now match the tables and check the network forwarding behaviour before w1\n+      return False\n+    return True\n+\n+  def find_per_packet_inconsistent(self, check_covered=False, summarize=True):\n     \"\"\"\n-    Returns 3 sets of packet traces. 1) all per-packet inconsistent traces\n-    2) traces ignored because they just race on the first switch\n-    3) summarized traces after removing traces that races with the same writes\n-    :param ignore_first:\n-    :param summarize:\n-    :return:\n+    Returns the following sets of packet traces.\n+      1) all packet traces that race with a write event\n+      2) all per-packet inconsistent traces (covered and uncovered)\n+      3) Covered packet traces (trace with races cannot happen because of HB)\n+      4) Packet traces with races with first switch on version update\n+      5) Summarize traces after removing covered and trimming traces that races with the same writes\n+\n+    all packet traces = all per-packet inconsistent traces +  Packet traces with races with first switch on version update\n+    summazied = all per-packet inconsistent traces - repeatd all per-packet inconsistent traces\n     \"\"\"\n     packet_races = self.get_all_packet_traces_with_races()\n+    all_inconsistent_packet_traces = []\n     inconsistent_packet_traces = []\n-    ignored_packet_traces = []\n+    inconsistent_packet_traces_covered = []\n+    inconsistent_packet_entry_version = []\n+    summarized = []\n+\n+    versions_by_dpid = {}\n+    for version, cmds in self.versions.iteritems():\n+      versions_by_dpid[version] = set([getattr(self.g.node[cmd]['event'], 'dpid', None) for cmd in cmds])\n+\n \n-    if ignore_first:\n-      for data in packet_races:\n-        just_first = data[2]\n-        if not just_first:\n-          inconsistent_packet_traces.append(data)\n+    def get_racing_versions(races):\n+      racing_versions = []\n+      for race in races:\n+        for version, cmds in self.versions.iteritems():\n+          if race.i_event.eid in cmds or race.k_event.eid in cmds:\n+            racing_versions.append(version)\n+      return list(set(racing_versions))\n+\n+    for trace, races in packet_races:\n+      # Then for sure this is a true inconsistent packet\n+      racing_versions = get_racing_versions(races)\n+      if len(races) > 1:\n+        all_inconsistent_packet_traces.append((trace, races, racing_versions))\n+        continue\n+\n+      race = races[0]\n+      trace_nodes = nx.dfs_preorder_nodes(trace, trace.graph['host_send'].eid)\n+      trace_dpids = [getattr(self.g.node[node]['event'], 'dpid', None) for node in trace_nodes]\n+      racing_dpid = race.i_event.dpid\n+      none_racing_dpids = trace_dpids[:trace_dpids.index(racing_dpid)]\n+      racing_version = racing_versions[0]\n+      # Check with the race on the first switch of the update\n+      if versions_by_dpid[racing_version].intersection(none_racing_dpids):\n+        all_inconsistent_packet_traces.append((trace, races, racing_versions))\n+      else:\n+        inconsistent_packet_entry_version.append((trace, races, racing_versions))\n+\n+    if check_covered:\n+      for trace, races, versions in all_inconsistent_packet_traces:\n+        ordered = list(nx.dfs_preorder_nodes(trace, trace.graph['host_send'].eid))\n+        if self.check_covered(ordered, races):\n+          inconsistent_packet_traces_covered.append((trace, races, versions))\n         else:\n-          ignored_packet_traces.append(data)\n+          inconsistent_packet_traces.append((trace, races, versions))\n     else:\n-      inconsistent_packet_traces = packet_races\n+      inconsistent_packet_traces = all_inconsistent_packet_traces\n \n-    summarized = []\n     if summarize:\n-      summarized = self.summarize_per_packet_inconsistent(\n-        inconsistent_packet_traces, add_just_first=not ignore_first)\n-\n-    return inconsistent_packet_traces, ignored_packet_traces, summarized\n+      summarized = self.summarize_per_packet_inconsistent(inconsistent_packet_traces)\n+    return packet_races, inconsistent_packet_traces, \\\n+           inconsistent_packet_traces_covered, \\\n+           inconsistent_packet_entry_version, summarized\n \n   def find_barrier_replies(self):\n     barrier_replies = []\n@@ -1085,7 +1161,7 @@ class HappensBeforeGraph(object):\n       if isinstance(v, HbMessageSend):\n         print \"React to Msg: \", v.msg_type_str\n       for cmd in cmds:\n-        node =  self.graph.g.node[cmd]['event']\n+        node =  self.g.node[cmd]['event']\n         match = ''\n         if getattr(node.msg, 'match', None):\n           match = node.msg.show().replace('\\n', ' ')\n@@ -1141,13 +1217,17 @@ class Main(object):\n     packet_traces = self.graph.extract_traces(self.graph.g)\n     t3 = time.time()\n \n-    inconsistent_packet_traces, ignored_packet_traces, summarized = self.graph.find_per_packet_inconsistent(self.ignore_first, True)\n+    reactive_cmds = self.graph.find_reactive_versions()\n     t4 = time.time()\n \n-    reactive_cmds = self.graph.find_reactive_versions()\n+    proactive_cmds = self.graph.find_proactive_cmds(reactive_cmds)\n+    versions = self.graph.find_versions()\n     t5 = time.time()\n \n-    proactive_cmds = self.graph.find_proactive_cmds(reactive_cmds)\n+    packet_races, inconsistent_packet_traces, \\\n+           inconsistent_packet_traces_covered, \\\n+           inconsistent_packet_entry_version, summarized = \\\n+      self.graph.find_per_packet_inconsistent(True, True)\n     t6 = time.time()\n \n     racing_versions = self.graph.find_inconsistent_updates()\n@@ -1160,18 +1240,26 @@ class Main(object):\n \n \n     # Print traces\n-    for data in inconsistent_packet_traces:\n-      self.graph.print_racing_packet_trace(*data, label='race')\n-    for data in summarized:\n-      self.graph.print_racing_packet_trace(*data, label='trimmed')\n-    for data in ignored_packet_traces:\n-      self.graph.print_racing_packet_trace(*data, label='ignored')\n+    for trace, races in packet_races:\n+      self.graph.print_racing_packet_trace(trace, races, label='race')\n+    for trace, races, _ in inconsistent_packet_traces:\n+      self.graph.print_racing_packet_trace(trace, races, label='inconsistent')\n+    for trace, races, _ in inconsistent_packet_traces_covered:\n+      self.graph.print_racing_packet_trace(trace, races, label='covered')\n+    for trace, races, _ in inconsistent_packet_entry_version:\n+      self.graph.print_racing_packet_trace(trace, races, label='entry')\n+    for trace, races, _ in summarized:\n+      self.graph.print_racing_packet_trace(trace, races, label='summarized')\n     self.graph.save_races_graph(self.print_pkt)\n \n-    versions = self.graph.find_versions()\n+\n     self.graph.print_versions(versions)\n \n+\n+    print \"Number of packet traces with races:\", len(packet_races)\n     print \"Number of packet inconsistencies: \", len(inconsistent_packet_traces)\n+    print \"Number of packet inconsistencies that are covered by HB: \", len(inconsistent_packet_traces_covered)\n+    print \"Number of packet traces that just races with the first version: \", len(inconsistent_packet_entry_version)\n     print \"Number of packet inconsistencies after trimming repeated races: \", len(summarized)\n     print \"Number of packet inconsistent updates: \", len(racing_versions)\n     print \"INCONSISENT updates\", racing_versions\n@@ -1179,9 +1267,9 @@ class Main(object):\n     load_time = t1 - t0\n     detect_races_time = t2 - t1\n     extract_traces_time = t3 - t2\n-    per_packet_inconsistent_time = t4 - t3\n-    find_reactive_cmds_time = t5 - t4\n-    find_proactive_cmds_time = t6 - t5\n+    find_reactive_cmds_time = t4 - t3\n+    find_proactive_cmds_time = t5 - t4\n+    per_packet_inconsistent_time = t6 - t5\n     find_inconsistent_update_time = t7 - t6\n \n \n@@ -1222,9 +1310,18 @@ class Main(object):\n     num_ww_time_edges = self.graph.race_detector.time_hb_ww_edges_counter\n     num_time_edges = num_rw_time_edges + num_ww_time_edges\n \n+    print \"Number of packet traces with races:\", len(packet_races)\n+    print \"Number of packet inconsistencies: \", len(inconsistent_packet_traces)\n+    print \"Number of packet inconsistencies that are covered by HB: \", len(inconsistent_packet_traces_covered)\n+    print \"Number of packet traces that just races with the first version: \", len(inconsistent_packet_entry_version)\n+    print \"Number of packet inconsistencies after trimming repeated races: \", len(summarized)\n+\n+\n+    num_per_pkt_races = len(packet_races)\n     num_per_pkt_inconsistent = len(inconsistent_packet_traces)\n+    num_per_pkt_inconsistent_covered = len(inconsistent_packet_traces_covered)\n+    num_per_pkt_race_version = len(inconsistent_packet_entry_version)\n     num_per_pkt_inconsistent_no_repeat = len(summarized)\n-    num_per_pkt_ignored_first = len(ignored_packet_traces)\n \n     with open(file_name, 'w') as f:\n       # General info\n@@ -1249,9 +1346,11 @@ class Main(object):\n       f.write('num_races,%d\\n' % num_races)\n \n       # Inconsistency\n-      f.write('num_per_pkt_inconsistent_no_repeat,%d\\n' % num_per_pkt_inconsistent_no_repeat)\n-      f.write('num_per_pkt_ignored_first,%d\\n' % num_per_pkt_ignored_first)\n+      f.write('num_per_pkt_races,%d\\n' % num_per_pkt_races)\n       f.write('num_per_pkt_inconsistent,%d\\n' % num_per_pkt_inconsistent)\n+      f.write('num_per_pkt_inconsistent_covered,%d\\n' % num_per_pkt_inconsistent_covered)\n+      f.write('num_per_pkt_race_version,%d\\n' % num_per_pkt_race_version)\n+      f.write('num_per_pkt_inconsistent_no_repeat,%d\\n' % num_per_pkt_inconsistent_no_repeat)\n \n       # Times\n       f.write('total_time_sec,%f\\n'% total_time)",
      "status": "On branch hb\nYour branch is up-to-date with 'origin/hb'.\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git checkout -- <file>...\" to discard changes in working directory)\n  (commit or discard the untracked or modified content in submodules)\n\n\tmodified:   config/fuzzer_params.py\n\tmodified:   config/trace_floodlight_hb_learningswitch.py\n\tmodified:   config/trace_pox_l2_consistency.py\n\tmodified:   config/trace_pox_l2_multi.py\n\tmodified:   pox (new commits, modified content, untracked content)\n\tmodified:   sts/happensbefore/hb_graph.py\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\n\tconfig/pox_consistency.py\n\tconfig/trace_onos_hb_learningswitch.py\n\tgen.sh~\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")"
    }
  },
  "sys": {
    "lsb_release": "Ubuntu 15.04",
    "uname": "Linux stsdev 3.19.0-26-generic #28-Ubuntu SMP Tue Aug 11 14:16:32 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux"
  },
  "timestamp": "2015_09_21_22_22_33",
  "user": "ahassany"
}
